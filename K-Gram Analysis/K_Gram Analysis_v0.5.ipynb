{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Gram Importance Analysis v0.5\n",
    "## Project Vigil - Malicious Prompt Detection\n",
    "## **K-Gram Feature Importance Using Pre-Trained Model**\n",
    "\n",
    "This notebook analyzes the importance of individual k-grams by measuring how model predictions change when each k-gram is removed (feature ablation analysis).\n",
    "\n",
    "### Overview\n",
    "- **Dataset**: MPDD.csv (Malicious Prompt Detection Dataset)\n",
    "- **Model**: Pre-trained classifier from Project-Vigil repository (NOT trained in this notebook!)\n",
    "- **Analysis**: K-gram importance via feature ablation\n",
    "- **Method**: Remove each k-gram and measure prediction change\n",
    "\n",
    "### What's New in v0.5\n",
    "**COMPLETELY DIFFERENT APPROACH**: This is NOT cross-validation!\n",
    "\n",
    "**What v0.5 Does:**\n",
    "1. Loads the **pre-trained model** (doesn't train a new one)\n",
    "2. Extracts k-grams from dataset\n",
    "3. For each k-gram:\n",
    "   - Removes that k-gram from feature vectors\n",
    "   - Gets predictions from pre-trained model\n",
    "   - Measures how predictions changed\n",
    "4. Ranks k-grams by importance\n",
    "\n",
    "**Why This is Fast:**\n",
    "- No model training (just predictions!)\n",
    "- Analyzes only top k-grams (configurable)\n",
    "- Can sample dataset (configurable)\n",
    "- Vectorized operations\n",
    "- Completes in minutes, not hours!\n",
    "\n",
    "### Author: Project Vigil Team\n",
    "### Version: 0.5 (K-Gram Feature Importance)\n",
    "### Date: 2025-11-16\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: This notebook is designed to run in Google Colab and will automatically download the dataset and pre-trained model from the GitHub repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if running in Colab)\n",
    "# !pip install -q scikit-learn pandas numpy matplotlib seaborn tqdm\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For downloading files from GitHub\n",
    "import urllib.request\n",
    "import ssl\n",
    "\n",
    "# Progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Setup\n",
    "\n",
    "### K-Gram Importance Analysis Configuration\n",
    "- **Analysis Method**: Feature Ablation (remove k-grams one at a time)\n",
    "- **Model**: Pre-trained (loaded, not trained)\n",
    "- **Speed Optimizations**: Configurable sample size and top-k features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub repository URLs for dataset and model\n",
    "GITHUB_REPO = \"https://raw.githubusercontent.com/Meet2304/Project-Vigil/claude/fix-kgram-dataset-01VTpiw6P21u1bbgrvx2rVb2\"\n",
    "DATASET_URL = f\"{GITHUB_REPO}/Dataset/MPDD.csv\"\n",
    "MODEL_URL = f\"{GITHUB_REPO}/Model/classifier.pkl\"\n",
    "\n",
    "# Local paths for downloaded files\n",
    "DATASET_PATH = \"MPDD.csv\"\n",
    "MODEL_PATH = \"classifier.pkl\"\n",
    "\n",
    "# K-gram configuration\n",
    "K_GRAM_CONFIG = {\n",
    "    'word_ngram_range': (1, 3),  # Word-level unigrams to trigrams\n",
    "    'max_features': 5000,        # Maximum number of features\n",
    "    'use_tfidf': True,           # Use TF-IDF\n",
    "    'analyzer': 'word'\n",
    "}\n",
    "\n",
    "# Analysis configuration\n",
    "ANALYSIS_CONFIG = {\n",
    "    'sample_size': 5000,         # Use 5000 samples for analysis (set to None for all data)\n",
    "    'top_k_features': 100,       # Analyze top 100 k-grams by frequency\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Dataset URL: {DATASET_URL}\")\n",
    "print(f\"  Model URL: {MODEL_URL}\")\n",
    "print(f\"\\nðŸ”¤ K-Gram Config:\")\n",
    "print(f\"  Analyzer: {K_GRAM_CONFIG['analyzer']}-level\")\n",
    "print(f\"  N-gram Range: {K_GRAM_CONFIG['word_ngram_range']}\")\n",
    "print(f\"  Max Features: {K_GRAM_CONFIG['max_features']}\")\n",
    "print(f\"\\nðŸ“Š Analysis Config:\")\n",
    "print(f\"  Sample Size: {ANALYSIS_CONFIG['sample_size'] if ANALYSIS_CONFIG['sample_size'] else 'All data'}\")\n",
    "print(f\"  Top K Features to Analyze: {ANALYSIS_CONFIG['top_k_features']}\")\n",
    "print(f\"  Random State: {ANALYSIS_CONFIG['random_state']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Dataset and Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url: str, local_path: str) -> bool:\n",
    "    \"\"\"Download a file from URL to local path.\"\"\"\n",
    "    try:\n",
    "        ssl_context = ssl.create_default_context()\n",
    "        ssl_context.check_hostname = False\n",
    "        ssl_context.verify_mode = ssl.CERT_NONE\n",
    "        \n",
    "        print(f\"Downloading {url}...\")\n",
    "        urllib.request.urlretrieve(url, local_path)\n",
    "        print(f\"âœ“ Downloaded to {local_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error downloading {url}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Download dataset\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    download_file(DATASET_URL, DATASET_PATH)\n",
    "else:\n",
    "    print(f\"âœ“ Dataset already exists at {DATASET_PATH}\")\n",
    "\n",
    "# Download pre-trained model\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    download_file(MODEL_URL, MODEL_PATH)\n",
    "else:\n",
    "    print(f\"âœ“ Model already exists at {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Dataset and Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "print(\"Loading MPDD dataset...\")\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "print(f\"âœ“ Dataset loaded: {df.shape[0]:,} samples\")\n",
    "\n",
    "# Sample dataset if configured\n",
    "if ANALYSIS_CONFIG['sample_size'] and ANALYSIS_CONFIG['sample_size'] < len(df):\n",
    "    print(f\"\\nSampling {ANALYSIS_CONFIG['sample_size']:,} samples for faster analysis...\")\n",
    "    df_sample = df.sample(\n",
    "        n=ANALYSIS_CONFIG['sample_size'],\n",
    "        random_state=ANALYSIS_CONFIG['random_state'],\n",
    "        stratify=df['isMalicious']  # Maintain class balance\n",
    "    )\n",
    "    print(f\"âœ“ Sampled dataset: {len(df_sample):,} samples\")\n",
    "else:\n",
    "    df_sample = df\n",
    "    print(f\"Using full dataset: {len(df_sample):,} samples\")\n",
    "\n",
    "# Extract texts and labels\n",
    "texts = df_sample['Prompt'].astype(str).tolist()\n",
    "labels = df_sample['isMalicious'].astype(int).tolist()\n",
    "\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"  Total samples: {len(texts):,}\")\n",
    "print(f\"  Malicious: {sum(labels):,} ({sum(labels)/len(labels)*100:.1f}%)\")\n",
    "print(f\"  Benign: {len(labels)-sum(labels):,} ({(len(labels)-sum(labels))/len(labels)*100:.1f}%)\")\n",
    "\n",
    "# Load pre-trained model\n",
    "print(f\"\\nLoading pre-trained model from {MODEL_PATH}...\")\n",
    "with open(MODEL_PATH, 'rb') as f:\n",
    "    classifier = pickle.load(f)\n",
    "\n",
    "print(f\"âœ“ Loaded pre-trained classifier: {type(classifier).__name__}\")\n",
    "print(f\"\\nâš ï¸  IMPORTANT: This model will NOT be retrained!\")\n",
    "print(f\"   We will only use it for predictions to analyze k-gram importance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract K-Grams and Create Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vectorizer\n",
    "print(\"Initializing TF-IDF vectorizer...\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer=K_GRAM_CONFIG['analyzer'],\n",
    "    ngram_range=K_GRAM_CONFIG['word_ngram_range'],\n",
    "    max_features=K_GRAM_CONFIG['max_features'],\n",
    "    lowercase=True,\n",
    "    strip_accents='unicode'\n",
    ")\n",
    "\n",
    "# Extract features\n",
    "print(f\"\\nExtracting k-grams from {len(texts):,} samples...\")\n",
    "X = vectorizer.fit_transform(texts)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"âœ“ Extracted features\")\n",
    "print(f\"  Feature matrix shape: {X.shape}\")\n",
    "print(f\"  ({X.shape[0]:,} samples Ã— {X.shape[1]:,} k-grams)\")\n",
    "print(f\"  Sparsity: {(1 - X.nnz / (X.shape[0] * X.shape[1]))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Get Baseline Predictions from Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get baseline predictions\n",
    "print(\"Getting baseline predictions from pre-trained model...\")\n",
    "y_pred_baseline = classifier.predict(X)\n",
    "y_proba_baseline = classifier.predict_proba(X) if hasattr(classifier, 'predict_proba') else None\n",
    "\n",
    "# Calculate baseline accuracy\n",
    "baseline_accuracy = accuracy_score(labels, y_pred_baseline)\n",
    "\n",
    "print(f\"\\nâœ“ Baseline Results (with all k-grams):\")\n",
    "print(f\"  Accuracy: {baseline_accuracy:.4f} ({baseline_accuracy*100:.2f}%)\")\n",
    "print(f\"  Correct predictions: {sum(y_pred_baseline == labels):,}/{len(labels):,}\")\n",
    "\n",
    "# Show confusion matrix\n",
    "cm = confusion_matrix(labels, y_pred_baseline)\n",
    "print(f\"\\n  Confusion Matrix:\")\n",
    "print(f\"    TN={cm[0,0]}, FP={cm[0,1]}\")\n",
    "print(f\"    FN={cm[1,0]}, TP={cm[1,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Identify Top K-Grams to Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance by frequency and class association\n",
    "print(f\"\\nAnalyzing k-grams to identify top {ANALYSIS_CONFIG['top_k_features']} most important...\")\n",
    "\n",
    "# Calculate mean TF-IDF per class\n",
    "y_array = np.array(labels)\n",
    "malicious_mask = y_array == 1\n",
    "benign_mask = y_array == 0\n",
    "\n",
    "malicious_mean = np.asarray(X[malicious_mask].mean(axis=0)).ravel()\n",
    "benign_mean = np.asarray(X[benign_mask].mean(axis=0)).ravel()\n",
    "\n",
    "# Calculate importance score (difference between classes)\n",
    "importance_scores = np.abs(malicious_mean - benign_mean)\n",
    "\n",
    "# Get top k features\n",
    "top_k_indices = importance_scores.argsort()[-ANALYSIS_CONFIG['top_k_features']:][::-1]\n",
    "top_k_features = [(feature_names[i], importance_scores[i], i) for i in top_k_indices]\n",
    "\n",
    "print(f\"\\nâœ“ Identified top {ANALYSIS_CONFIG['top_k_features']} k-grams\")\n",
    "print(f\"\\nTop 20 Most Important K-Grams:\")\n",
    "print(\"=\" * 70)\n",
    "for rank, (feature, score, idx) in enumerate(top_k_features[:20], 1):\n",
    "    n_words = len(feature.split())\n",
    "    gram_type = \"unigram\" if n_words == 1 else (\"bigram\" if n_words == 2 else \"trigram\")\n",
    "    mal_score = malicious_mean[idx]\n",
    "    ben_score = benign_mean[idx]\n",
    "    bias = \"MALICIOUS\" if mal_score > ben_score else \"BENIGN\"\n",
    "    print(f\"{rank:3d}. '{feature}' ({gram_type})\")\n",
    "    print(f\"      Score: {score:.4f} | Bias: {bias} | Mal: {mal_score:.4f}, Ben: {ben_score:.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. K-Gram Ablation Analysis\n",
    "\n",
    "### Feature Ablation Method\n",
    "For each top k-gram:\n",
    "1. Create a modified feature matrix with that k-gram removed (set to 0)\n",
    "2. Get predictions from pre-trained model on modified features\n",
    "3. Compare to baseline predictions\n",
    "4. Measure impact:\n",
    "   - Accuracy change\n",
    "   - Number of prediction flips\n",
    "   - Confidence changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KGramImportanceAnalyzer:\n",
    "    \"\"\"Analyze k-gram importance via feature ablation.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, X, y_true, y_pred_baseline, y_proba_baseline):\n",
    "        self.model = model\n",
    "        self.X = X.copy()  # Sparse matrix\n",
    "        self.y_true = np.array(y_true)\n",
    "        self.y_pred_baseline = np.array(y_pred_baseline)\n",
    "        self.y_proba_baseline = y_proba_baseline\n",
    "        self.baseline_accuracy = accuracy_score(y_true, y_pred_baseline)\n",
    "        self.results = []\n",
    "    \n",
    "    def analyze_feature(self, feature_idx: int, feature_name: str) -> Dict:\n",
    "        \"\"\"Analyze importance of a single feature by removing it.\"\"\"\n",
    "        # Create modified matrix with this feature removed (set to 0)\n",
    "        X_modified = self.X.copy()\n",
    "        X_modified[:, feature_idx] = 0\n",
    "        \n",
    "        # Get predictions without this feature\n",
    "        y_pred_ablated = self.model.predict(X_modified)\n",
    "        y_proba_ablated = self.model.predict_proba(X_modified) if hasattr(self.model, 'predict_proba') else None\n",
    "        \n",
    "        # Calculate metrics\n",
    "        ablated_accuracy = accuracy_score(self.y_true, y_pred_ablated)\n",
    "        accuracy_drop = self.baseline_accuracy - ablated_accuracy\n",
    "        \n",
    "        # Count prediction flips\n",
    "        prediction_flips = np.sum(y_pred_ablated != self.y_pred_baseline)\n",
    "        flip_rate = prediction_flips / len(self.y_true)\n",
    "        \n",
    "        # Analyze confidence changes\n",
    "        if y_proba_ablated is not None and self.y_proba_baseline is not None:\n",
    "            # Get probability of predicted class\n",
    "            baseline_conf = np.array([self.y_proba_baseline[i, self.y_pred_baseline[i]] \n",
    "                                     for i in range(len(self.y_pred_baseline))])\n",
    "            ablated_conf = np.array([y_proba_ablated[i, self.y_pred_baseline[i]] \n",
    "                                    for i in range(len(self.y_pred_baseline))])\n",
    "            conf_change = np.mean(baseline_conf - ablated_conf)\n",
    "        else:\n",
    "            conf_change = None\n",
    "        \n",
    "        # Analyze which class is affected more\n",
    "        mal_mask = self.y_true == 1\n",
    "        ben_mask = self.y_true == 0\n",
    "        \n",
    "        mal_flips = np.sum((y_pred_ablated != self.y_pred_baseline) & mal_mask)\n",
    "        ben_flips = np.sum((y_pred_ablated != self.y_pred_baseline) & ben_mask)\n",
    "        \n",
    "        return {\n",
    "            'feature_name': feature_name,\n",
    "            'feature_idx': feature_idx,\n",
    "            'baseline_accuracy': self.baseline_accuracy,\n",
    "            'ablated_accuracy': ablated_accuracy,\n",
    "            'accuracy_drop': accuracy_drop,\n",
    "            'prediction_flips': prediction_flips,\n",
    "            'flip_rate': flip_rate,\n",
    "            'malicious_flips': mal_flips,\n",
    "            'benign_flips': ben_flips,\n",
    "            'confidence_change': conf_change\n",
    "        }\n",
    "    \n",
    "    def analyze_top_features(self, top_features: List[Tuple], verbose: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"Analyze all top features.\"\"\"\n",
    "        if verbose:\n",
    "            print(\"=\" * 70)\n",
    "            print(\"K-GRAM ABLATION ANALYSIS\")\n",
    "            print(\"=\" * 70)\n",
    "            print(f\"Analyzing {len(top_features)} k-grams...\")\n",
    "            print(f\"For each k-gram: Remove it and measure prediction changes\")\n",
    "            print(\"=\" * 70)\n",
    "            print()\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for feature_name, _, feature_idx in tqdm(top_features, desc=\"ðŸ”¬ Analyzing K-Grams\"):\n",
    "            result = self.analyze_feature(feature_idx, feature_name)\n",
    "            results.append(result)\n",
    "        \n",
    "        self.results = pd.DataFrame(results)\n",
    "        return self.results\n",
    "\n",
    "print(\"âœ“ KGramImportanceAnalyzer class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Run K-Gram Ablation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analyzer\n",
    "analyzer = KGramImportanceAnalyzer(\n",
    "    model=classifier,\n",
    "    X=X,\n",
    "    y_true=labels,\n",
    "    y_pred_baseline=y_pred_baseline,\n",
    "    y_proba_baseline=y_proba_baseline\n",
    ")\n",
    "\n",
    "# Run analysis\n",
    "start_time = time.time()\n",
    "results_df = analyzer.analyze_top_features(top_k_features, verbose=True)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nâœ“ Analysis completed in {elapsed_time:.2f} seconds\")\n",
    "print(f\"  Average time per k-gram: {elapsed_time/len(top_k_features):.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Analysis Results - Most Important K-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by accuracy drop (most important = biggest drop)\n",
    "results_sorted = results_df.sort_values('accuracy_drop', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TOP K-GRAMS BY IMPORTANCE (Ranked by Accuracy Drop When Removed)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nBaseline Accuracy (with all k-grams): {baseline_accuracy:.4f}\\n\")\n",
    "\n",
    "print(\"Rank | K-Gram | Acc Drop | Pred Flips | Flip Rate\")\n",
    "print(\"-\" * 70)\n",
    "for rank, (idx, row) in enumerate(results_sorted.head(20).iterrows(), 1):\n",
    "    print(f\"{rank:3d}. | '{row['feature_name'][:30]}' | \"\n",
    "          f\"{row['accuracy_drop']:+.4f} | \"\n",
    "          f\"{int(row['prediction_flips']):5d} | \"\n",
    "          f\"{row['flip_rate']*100:5.2f}%\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Show detailed stats for top 5\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DETAILED ANALYSIS: Top 5 Most Important K-Grams\")\n",
    "print(\"=\" * 70)\n",
    "for rank, (idx, row) in enumerate(results_sorted.head(5).iterrows(), 1):\n",
    "    print(f\"\\n{rank}. K-Gram: '{row['feature_name']}'\")\n",
    "    print(f\"   Baseline Accuracy: {row['baseline_accuracy']:.4f}\")\n",
    "    print(f\"   Accuracy WITHOUT this k-gram: {row['ablated_accuracy']:.4f}\")\n",
    "    print(f\"   Accuracy Drop: {row['accuracy_drop']:+.4f} ({row['accuracy_drop']*100:+.2f}%)\")\n",
    "    print(f\"   Prediction Flips: {int(row['prediction_flips'])} ({row['flip_rate']*100:.2f}%)\")\n",
    "    print(f\"   Malicious Flips: {int(row['malicious_flips'])}\")\n",
    "    print(f\"   Benign Flips: {int(row['benign_flips'])}\")\n",
    "    if row['confidence_change'] is not None:\n",
    "        print(f\"   Avg Confidence Change: {row['confidence_change']:+.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualization: K-Gram Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top k-grams by accuracy drop\n",
    "top_20 = results_sorted.head(20)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "bars = plt.barh(range(len(top_20)), top_20['accuracy_drop'] * 100)\n",
    "\n",
    "# Color bars by impact (red = negative, green = positive)\n",
    "for i, bar in enumerate(bars):\n",
    "    if top_20.iloc[i]['accuracy_drop'] < 0:\n",
    "        bar.set_color('green')\n",
    "    else:\n",
    "        bar.set_color('red')\n",
    "\n",
    "plt.yticks(range(len(top_20)), top_20['feature_name'], fontsize=10)\n",
    "plt.xlabel('Accuracy Drop When K-Gram Removed (%)', fontsize=12)\n",
    "plt.title('K-Gram Importance: Top 20 Features by Prediction Impact', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Interpretation:\")\n",
    "print(\"  â€¢ Red bars (positive): Removing this k-gram DECREASES accuracy (important for correct predictions)\")\n",
    "print(\"  â€¢ Green bars (negative): Removing this k-gram INCREASES accuracy (may be misleading/noisy)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualization: Prediction Flip Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction flips by class\n",
    "top_20 = results_sorted.head(20)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Total prediction flips\n",
    "ax1.barh(range(len(top_20)), top_20['prediction_flips'], color='steelblue')\n",
    "ax1.set_yticks(range(len(top_20)))\n",
    "ax1.set_yticklabels(top_20['feature_name'], fontsize=9)\n",
    "ax1.set_xlabel('Number of Prediction Flips', fontsize=11)\n",
    "ax1.set_title('Total Prediction Changes When K-Gram Removed', fontsize=12, fontweight='bold')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Plot 2: Prediction flips by class\n",
    "width = 0.35\n",
    "y_pos = np.arange(len(top_20))\n",
    "ax2.barh(y_pos - width/2, top_20['malicious_flips'], width, label='Malicious', color='red', alpha=0.7)\n",
    "ax2.barh(y_pos + width/2, top_20['benign_flips'], width, label='Benign', color='green', alpha=0.7)\n",
    "ax2.set_yticks(y_pos)\n",
    "ax2.set_yticklabels(top_20['feature_name'], fontsize=9)\n",
    "ax2.set_xlabel('Number of Prediction Flips', fontsize=11)\n",
    "ax2.set_title('Prediction Changes by Class', fontsize=12, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"K-GRAM IMPORTANCE ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nDataset:\")\n",
    "print(f\"  Samples Analyzed: {len(labels):,}\")\n",
    "print(f\"  K-Grams Analyzed: {len(results_df)}\")\n",
    "print(f\"\\nBaseline Performance (All K-Grams):\")\n",
    "print(f\"  Accuracy: {baseline_accuracy:.4f} ({baseline_accuracy*100:.2f}%)\")\n",
    "print(f\"\\nImpact Statistics:\")\n",
    "print(f\"  K-Grams with NEGATIVE impact (decrease accuracy): {sum(results_df['accuracy_drop'] > 0)}\")\n",
    "print(f\"  K-Grams with POSITIVE impact (increase accuracy): {sum(results_df['accuracy_drop'] < 0)}\")\n",
    "print(f\"  K-Grams with NO impact: {sum(results_df['accuracy_drop'] == 0)}\")\n",
    "print(f\"\\nTop Impact:\")\n",
    "print(f\"  Max Accuracy Drop: {results_df['accuracy_drop'].max():+.4f} ({results_df['accuracy_drop'].max()*100:+.2f}%)\")\n",
    "print(f\"  Max Accuracy Gain: {results_df['accuracy_drop'].min():+.4f} ({results_df['accuracy_drop'].min()*100:+.2f}%)\")\n",
    "print(f\"  Avg Accuracy Change: {results_df['accuracy_drop'].mean():+.4f}\")\n",
    "print(f\"\\nPrediction Flips:\")\n",
    "print(f\"  Max Flips by Single K-Gram: {int(results_df['prediction_flips'].max())}\")\n",
    "print(f\"  Avg Flips per K-Gram: {results_df['prediction_flips'].mean():.1f}\")\n",
    "print(f\"  Total Unique Flips Across All K-Grams: {results_df['prediction_flips'].sum():,.0f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to CSV\n",
    "results_df.to_csv('kgram_importance_results.csv', index=False)\n",
    "print(\"âœ“ Results saved to 'kgram_importance_results.csv'\")\n",
    "\n",
    "# Export summary to JSON\n",
    "summary = {\n",
    "    'analysis_config': ANALYSIS_CONFIG,\n",
    "    'kgram_config': K_GRAM_CONFIG,\n",
    "    'dataset_size': len(labels),\n",
    "    'kgrams_analyzed': len(results_df),\n",
    "    'baseline_accuracy': float(baseline_accuracy),\n",
    "    'top_10_important_kgrams': [\n",
    "        {\n",
    "            'rank': rank,\n",
    "            'kgram': row['feature_name'],\n",
    "            'accuracy_drop': float(row['accuracy_drop']),\n",
    "            'prediction_flips': int(row['prediction_flips'])\n",
    "        }\n",
    "        for rank, (_, row) in enumerate(results_sorted.head(10).iterrows(), 1)\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('kgram_importance_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(\"âœ“ Summary saved to 'kgram_importance_summary.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Conclusions\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "This analysis reveals:\n",
    "1. **Which k-grams are most critical** for the model's predictions\n",
    "2. **How removing each k-gram affects accuracy** (positive or negative impact)\n",
    "3. **Which predictions change** when specific k-grams are removed\n",
    "4. **Class-specific importance** (affects malicious vs benign differently)\n",
    "\n",
    "### Interpretation Guide\n",
    "\n",
    "**K-Grams with HIGH positive accuracy drop** (removing them DECREASES accuracy):\n",
    "- These are CRITICAL features for correct predictions\n",
    "- The model heavily relies on these patterns\n",
    "- Example: Words like \"ignore\", \"bypass\", \"override\"\n",
    "\n",
    "**K-Grams with negative accuracy drop** (removing them INCREASES accuracy):\n",
    "- These may be MISLEADING features\n",
    "- Could indicate overfitting or noise\n",
    "- Worth investigating further\n",
    "\n",
    "**K-Grams with many prediction flips**:\n",
    "- These affect many samples\n",
    "- High leverage in the model\n",
    "- Important for understanding model behavior\n",
    "\n",
    "### Key Differences from v0.4\n",
    "\n",
    "| Aspect | v0.4 (Cross-Validation) | v0.5 (Feature Importance) |\n",
    "|--------|------------------------|---------------------------|\n",
    "| **Model** | Trains NEW models | Uses PRE-TRAINED model |\n",
    "| **Analysis** | Model generalization | K-gram importance |\n",
    "| **Output** | Accuracy metrics | Feature rankings |\n",
    "| **Time** | Minutes | Minutes |\n",
    "| **Purpose** | Evaluate model | Understand features |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Investigate top k-grams**: Why are they important?\n",
    "2. **Examine negative impact k-grams**: Are they noise?\n",
    "3. **Feature engineering**: Can we improve based on insights?\n",
    "4. **Adversarial testing**: Can attackers avoid these k-grams?\n",
    "\n",
    "---\n",
    "\n",
    "**Project Vigil - Understanding What Makes Prompts Malicious**\n",
    "\n",
    "*v0.5: Feature importance through ablation analysis using the pre-trained model*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
